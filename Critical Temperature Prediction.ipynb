{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPj28CrLLem+7v4C1fM+lWQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"165FKQI9_y3J","executionInfo":{"status":"ok","timestamp":1739646301001,"user_tz":300,"elapsed":18090,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"fce41e44-07f1-41e7-af6b-4d12c2a476d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["!pip uninstall -y scikit-learn\n","!pip install scikit-learn==1.5.2\n","!pip install catboost\n","!pip install dcor\n","!pip install deap\n","\n","\n","import dcor\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","import numpy as np\n","import os\n","from tqdm import tqdm\n","from joblib import Parallel, delayed\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, mutual_info_classif, mutual_info_regression, VarianceThreshold\n","from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, KFold\n","from sklearn.metrics import mean_squared_error, r2_score, mutual_info_score, accuracy_score\n","from sklearn.utils import shuffle\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Input, Permute, Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout, LSTM\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from lightgbm.sklearn import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n","from xgboost import XGBRegressor, XGBClassifier\n","from sklearn.linear_model import Ridge, Lasso\n","\n","from deap import base, creator, tools, algorithms  # Genetic Algorithm library\n","import random\n","\n","from scipy.stats import spearmanr\n","from scipy.cluster.hierarchy import linkage, fcluster\n","import shap\n","from scipy.spatial.distance import correlation\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3_vTUuw_6vt","executionInfo":{"status":"ok","timestamp":1739647562147,"user_tz":300,"elapsed":12045,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"1c9c21aa-ed9e-4a03-e533-448c015f07a9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: scikit-learn 1.5.2\n","Uninstalling scikit-learn-1.5.2:\n","  Successfully uninstalled scikit-learn-1.5.2\n","Collecting scikit-learn==1.5.2\n","  Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.5.0)\n","Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","Installing collected packages: scikit-learn\n","Successfully installed scikit-learn-1.5.2\n","Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n","Requirement already satisfied: dcor in /usr/local/lib/python3.11/dist-packages (0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from dcor) (1.26.4)\n","Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.11/dist-packages (from dcor) (0.61.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from dcor) (1.13.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from dcor) (1.4.2)\n","Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51->dcor) (0.44.0)\n","Requirement already satisfied: deap in /usr/local/lib/python3.11/dist-packages (1.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (1.26.4)\n"]}]},{"cell_type":"code","source":["#Import data\n","train = pd.read_csv(\"gdrive/MyDrive/Learning/Superconductivity/train.csv\")\n","formula_train = pd.read_csv(\"gdrive/MyDrive/Learning/Superconductivity/formula_train.csv\")\n","print(f\"Train dataset shape: {train.shape}\")\n","print(f\"Train_formula dataset shape: {formula_train.shape}\")\n","\n","test = pd.read_csv(\"gdrive/MyDrive/Learning/Superconductivity/test.csv\")\n","formula_test = pd.read_csv(\"gdrive/MyDrive/Learning/Superconductivity/formula_test.csv\")\n","print(f\"Test dataset shape: {test.shape}\")\n","print(f\"Test_formula dataset shape: {formula_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbthpjVJBIAg","executionInfo":{"status":"ok","timestamp":1739646768258,"user_tz":300,"elapsed":2075,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"a430afe7-2364-4d47-cdef-27a66a1f9039"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset shape: (17010, 82)\n","Train_formula dataset shape: (17010, 88)\n","Test dataset shape: (4253, 81)\n","Test_formula dataset shape: (4253, 87)\n"]}]},{"cell_type":"markdown","source":["**Part 1: Using CNNs to predict temperature based on formula data**"],"metadata":{"id":"-bH37cg9GkT4"}},{"cell_type":"code","source":["#Set up architecture to train formula data on relevant column\n","material_elements = formula_train.drop(columns=[\"material\"])\n","material_elements = material_elements.astype(float)\n","\n","element_features = pd.read_csv(\"gdrive/MyDrive/Learning/Superconductivity/element_data.csv\")\n","del element_features['Unnamed: 0']"],"metadata":{"id":"SQzBdXzTBqd-","executionInfo":{"status":"ok","timestamp":1739646843446,"user_tz":300,"elapsed":188,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to store merged data\n","merged_data = []\n","targets = []\n","\n","# Iterate through each material in material_elements with a progress bar\n","for material_index, material_row in tqdm(material_elements.iterrows(), total=len(material_elements), desc=\"Processing materials\"):\n","    material_name = material_row.name  # Material is the index (name) of the row\n","    critical_temp = material_row['critical_temp']  # Get the target variable\n","    material_row = material_row.drop('critical_temp')  # Remove the target variable from the row\n","    # Get the non-zero element counts for this material\n","    elements_in_material = material_row[material_row > 0].index.tolist()  # List of elements in material with non-zero counts\n","\n","    # Create a temporary DataFrame for the current material\n","    material_data = []\n","\n","    for i in range(10):  # Maximum 10 rows per material\n","        if i < len(elements_in_material):\n","            element = elements_in_material[i]\n","            element_info = element_features[element_features['Element'] == element].copy()\n","            # Add element count (how many times this element occurs) to the feature data\n","            element_info['count'] = material_row[element]\n","        else:\n","            # Fill with zeros for padding\n","            element_info = pd.DataFrame(np.zeros((1, len(element_features.columns) + 1)),\n","                                        columns=element_features.columns.tolist() + ['count'])\n","\n","        # Append the element's features to the material data\n","        material_data.append(element_info)\n","\n","    # Combine material data into a single DataFrame for this material\n","    material_df = pd.concat(material_data, ignore_index=True)\n","    material_df['material_name'] = material_name  # Add the material name as a column\n","\n","    # Append the material's data to the merged dataset\n","    merged_data.append(material_df)\n","    targets.append(critical_temp)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0H8X0fw2CA-y","executionInfo":{"status":"ok","timestamp":1739647374386,"user_tz":300,"elapsed":140314,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"37d751db-5be8-4971-8cb2-9d13bb677e0a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing materials: 100%|██████████| 17010/17010 [02:20<00:00, 121.25it/s]\n"]}]},{"cell_type":"code","source":["# Combine all material data into a single DataFrame\n","features = ['count','AtomicMass','AtomicNumber','FirstIonizationEnergy','AtomicRadius','BoilingPoint',\n","            'Density','ElectronAffinity','Electronegativity','FusionHeat','MeltingPoint','SpecificHeat',\n","            'ThermalConductivity','ThermalExpansion','Valence','MolarVolume','Period', 'material_name'\n","]\n","final_df = pd.concat(merged_data, ignore_index=True)\n","formula_df = final_df[features]\n","\n","# Group by material_name to get arrays for CNN\n","grouped_fixed = []\n","for material_name, group in formula_df.groupby('material_name'):\n","    arr = group.drop(['material_name'], axis=1).values\n","    grouped_fixed.append(arr)\n","\n","X = np.array(grouped_fixed).reshape(-1, 10, 17)\n","X = np.nan_to_num(X, nan=0.0)\n","y = np.array(targets)\n","\n","print(f\"X.shape: {X.shape}, y.shape: {y.shape}\")  # Should be (samples, 10, 17) and (samples,) for targets\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUe_BOBwCKV4","executionInfo":{"status":"ok","timestamp":1739647446294,"user_tz":300,"elapsed":11747,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"b4e54806-e873-473a-9671-37c46dce6156"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["X.shape: (17010, 10, 17), y.shape: (17010,)\n"]}]},{"cell_type":"code","source":["X_flat = X.reshape(-1, X.shape[-1])  # Now X_flat has shape (17000 * 10, 17)\n","\n","# Initialize the StandardScaler\n","scaler = StandardScaler()\n","\n","# Fit and transform the features\n","X_scaled_flat = scaler.fit_transform(X_flat)\n","\n","# Reshape back to the original 3D shape: (17000, 10, 17)\n","X_new = X_scaled_flat.reshape(X.shape)"],"metadata":{"id":"0qXS0zXvCV78","executionInfo":{"status":"ok","timestamp":1739647496955,"user_tz":300,"elapsed":173,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["X_dup = np.concatenate([X_new] * 5, axis=0)  # Shape will be (85000, 10, 17)\n","y_dup = np.concatenate([y] * 5, axis=0)  # Shape will be (85000,)\n","\n","# Shuffle both X_dup and y_dup together while keeping alignment\n","X, y = shuffle(X_dup, y_dup, random_state=42)"],"metadata":{"id":"aU8VsWtwCZzF","executionInfo":{"status":"ok","timestamp":1739647655953,"user_tz":300,"elapsed":120,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Define CNN models\n","def build_cnn_c1():\n","    model = Sequential([\n","        Input(shape=(10, 17)),\n","        Permute((2, 1)),\n","        Conv1D(64, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(64, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        MaxPooling1D(2),\n","        Dropout(0.4),\n","        Conv1D(128, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(128, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        MaxPooling1D(2),\n","        Dropout(0.4),\n","        Conv1D(256, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(256, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        Flatten(),\n","        Dense(128, activation='swish', kernel_regularizer=l2(0.0001)),\n","        Dropout(0.4),\n","        Dense(1)\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n","    return model\n","\n","def build_cnn_c2():\n","    model = Sequential([\n","        Input(shape=(10, 17)),\n","        Conv1D(32, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(32, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        MaxPooling1D(2),\n","        Dropout(0.4),\n","        Conv1D(64, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(64, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        MaxPooling1D(2),\n","        Dropout(0.4),\n","        Conv1D(128, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(128, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        Flatten(),\n","        Dense(128, activation='swish', kernel_regularizer=l2(0.0001)),\n","        Dropout(0.4),\n","        Dense(1)\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n","    return model\n","\n","def build_cnn_c3():\n","    model = Sequential([\n","        Input(shape=(10, 17)),\n","        Permute((2, 1)),\n","        Conv1D(32, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(32, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        MaxPooling1D(2),\n","        Dropout(0.4),\n","        Conv1D(64, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(64, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        MaxPooling1D(2),\n","        Dropout(0.4),\n","        Conv1D(128, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        BatchNormalization(),\n","        Conv1D(128, 5, activation='swish', padding='same', kernel_regularizer=l2(0.0001)),\n","        Flatten(),\n","        Dense(128, activation='swish', kernel_regularizer=l2(0.0001)),\n","        Dropout(0.4),\n","        Dense(1)\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n","    return model\n","\n","def build_lstm_r1():\n","    model = Sequential([\n","        Input(shape=(10, 17)),\n","        LSTM(64, return_sequences=True, kernel_regularizer=l2(0.0001)),\n","        LSTM(32, return_sequences=True, kernel_regularizer=l2(0.0001)),\n","        LSTM(32, return_sequences=False, kernel_regularizer=l2(0.0001)),\n","        Flatten(),\n","        Dense(128, activation='swish', kernel_regularizer=l2(0.0001)),\n","        Dropout(0.4),\n","        Dense(1)\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n","    return model\n","\n","# Instantiate models\n","model_c1 = build_cnn_c1()\n","model_c2 = build_cnn_c2()\n","model_c3 = build_cnn_c3()\n","model_r1 = build_lstm_r1()\n","\n","\n"],"metadata":{"id":"QDgcE1tOCiU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Split data to train and test\n","X, X_test_final, y, y_test_final = train_test_split(X, y, test_size=0.1, random_state=42)"],"metadata":{"id":"bkDGFD5NCknN","executionInfo":{"status":"ok","timestamp":1739647663761,"user_tz":300,"elapsed":133,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#Train models\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n","model_c1 = build_cnn_c1()\n","model_c2 = build_cnn_c2()\n","model_c3 = build_cnn_c3()\n","model_r1 = build_lstm_r1()\n","\n","for train_index, test_index in kf.split(X):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","    # Compile the model\n","    model_c1.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  # Use 'mae' if\n","    # Train the model\n","    model_c1.fit(X_train, y_train, epochs=100, batch_size=200, validation_data=(X_test, y_test),\n","              callbacks=[early_stop])\n","\n","for train_index, test_index in kf.split(X):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","        # Compile the model\n","    model_c2.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  # Use 'mae' if needed\n","    # Train the model\n","    model_c2.fit(X_train, y_train, epochs=100, batch_size=200, validation_data=(X_test, y_test),\n","              callbacks=[early_stop])\n","\n","for train_index, test_index in kf.split(X):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","    model_c3.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  # Use 'mae' if needed\n","    # Train the model\n","    model_c3.fit(X_train, y_train, epochs=100, batch_size=200, validation_data=(X_test, y_test),\n","              callbacks=[early_stop])\n","\n","for train_index, test_index in kf.split(X):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","    model_r1.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  # Use 'mae' if needed\n","    # Train the model\n","    model_r1.fit(X_train, y_train, epochs=100, batch_size=200, validation_data=(X_test, y_test),\n","              callbacks=[early_stop])\n","# Save models\n","model_c1.save('gdrive/MyDrive/Learning/Superconductivity/cnn_c1.keras')\n","model_c2.save('gdrive/MyDrive/Learning/Superconductivity/cnn_c2.keras')\n","model_c3.save('gdrive/MyDrive/Learning/Superconductivity/cnn_c3.keras')\n","model_r1.save('gdrive/MyDrive/Learning/Superconductivity/lstm_r1.keras')\n"],"metadata":{"id":"zhNyqMYjCn5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load models\n","model_c1 = load_model('gdrive/MyDrive/Learning/Superconductivity/cnn_c1.keras')\n","model_c2 = load_model('gdrive/MyDrive/Learning/Superconductivity/cnn_c2.keras')\n","model_c3 = load_model('gdrive/MyDrive/Learning/Superconductivity/cnn_c3.keras')\n","model_r1 = load_model('gdrive/MyDrive/Learning/Superconductivity/lstm_r1.keras')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2h90DRTZC5Qu","executionInfo":{"status":"ok","timestamp":1739647873555,"user_tz":300,"elapsed":34299,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"f9a434ff-9cfd-4ab8-e6f0-aeca06180609"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step\n","\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n","MSE for model_c1: 69.75878036217281\n","MSE for model_c2: 71.94456800607736\n","MSE for model_c3: 95.01865296367131\n","MSE for model_r1: 47.898437589383775\n"]}]},{"cell_type":"code","source":["# Use a single test set\n","X_train, X_test, y_train, y_test = train_test_split(X_test_final, y_test_final, test_size=0.2, random_state=42)\n","\n","# Generate predictions from base models\n","y_pred_c1_train = model_c1.predict(X_train).reshape(-1)\n","y_pred_c2_train = model_c2.predict(X_train).reshape(-1)\n","y_pred_r1_train = model_r1.predict(X_train).reshape(-1)\n","\n","y_pred_c1_test = model_c1.predict(X_test).reshape(-1)\n","y_pred_c2_test = model_c2.predict(X_test).reshape(-1)\n","y_pred_r1_test = model_r1.predict(X_test).reshape(-1)\n","\n","# Create feature matrix for Ridge Regression (stacked predictions)\n","X_meta_train = np.column_stack([y_pred_c1_train, y_pred_c2_train, y_pred_r1_train])\n","X_meta_test = np.column_stack([y_pred_c1_test, y_pred_c2_test, y_pred_r1_test])\n","\n","# Train Ridge Regression as meta-learner\n","ridge = Ridge(alpha=1.0)\n","ridge.fit(X_meta_train, y_train)\n","\n","# Make final predictions using the meta-learner\n","y_pred_ensemble = ridge.predict(X_meta_test)\n","\n","# Compute MSE\n","mse_c1 = mean_squared_error(y_test, y_pred_c1_test)\n","mse_c2 = mean_squared_error(y_test, y_pred_c2_test)\n","mse_r1 = mean_squared_error(y_test, y_pred_r1_test)\n","mse_ensemble = mean_squared_error(y_test, y_pred_ensemble)\n","\n","# Print results\n","print(f\"MSE for model_c1: {mse_c1}\")\n","print(f\"MSE for model_c2: {mse_c2}\")\n","print(f\"MSE for model_r1: {mse_r1}\")\n","print(f\"MSE for Ridge ensemble: {mse_ensemble}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyIPSNAkcmF0","executionInfo":{"status":"ok","timestamp":1739653973786,"user_tz":300,"elapsed":22395,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"d4ead1ce-e743-4be9-cffc-f35ff1e9a5fa"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 64ms/step\n","\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n","\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","MSE for model_c1: 63.523222840028524\n","MSE for model_c2: 68.98727246912964\n","MSE for model_r1: 45.27766902237446\n","MSE for Ridge ensemble: 45.154098155313\n"]}]},{"cell_type":"markdown","source":["**Part 2: Using XGB Regressor to predict temperature based on provided material data**"],"metadata":{"id":"Y6GWLqg0Gzh6"}},{"cell_type":"code","source":["def preprocess_data(df, target_column):\n","    X = df.drop(columns=[target_column])\n","    y = df[target_column]\n","    keep_cols = X.nunique()[X.nunique()/1.0 != 1.0].index.tolist()\n","    X = X[keep_cols]\n","    return train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","def standardize_features(X_train, X_test):\n","    scaler = StandardScaler()\n","    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n","    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n","    return X_train_scaled, X_test_scaled"],"metadata":{"id":"7drOCnJdFOQ9","executionInfo":{"status":"ok","timestamp":1739650640277,"user_tz":300,"elapsed":84,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = preprocess_data(df=train, target_column='critical_temp')\n","X_train, X_test = standardize_features(X_train, X_test)"],"metadata":{"id":"_Acn8mrmHH85","executionInfo":{"status":"ok","timestamp":1739650641143,"user_tz":300,"elapsed":187,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# Train XGB Model\n","model = XGBRegressor(n_estimators=300,subsample=0.6, reg_lambda=1,\n","                                reg_alpha=0.1,min_child_weight=5, max_depth=10,\n","                                learning_rate=0.05, gamma=0.5, colsample_bytree=0.8,\n","                                random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Compute SHAP Values\n","explainer = shap.TreeExplainer(model)\n","shap_values = explainer.shap_values(X_train)\n","\n","y_pred = model.predict(X_test)\n","name = 'XGB'\n","print(f\"{name} MSE: {mean_squared_error(y_test, y_pred)}\")\n","print(f\"{name} R²: {r2_score(y_test, y_pred)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yH4IKe3lHR-6","executionInfo":{"status":"ok","timestamp":1739648895013,"user_tz":300,"elapsed":386462,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"1c888383-9009-4f09-9107-99fed8290845"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["XGB MSE: 81.46099460041265\n","XGB R²: 0.9280445120080448\n"]}]},{"cell_type":"code","source":["shap_importance = np.abs(shap_values).mean(axis=0)\n","feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'SHAP_Importance': shap_importance})\n","feature_importance_df = feature_importance_df.sort_values(by=\"SHAP_Importance\", ascending=False)\n","feature_importance_df.set_index('Feature', inplace=True)"],"metadata":{"id":"fEyoVUj2IaGu","executionInfo":{"status":"ok","timestamp":1739649055433,"user_tz":300,"elapsed":74,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mutual_info_score\n","from joblib import Parallel, delayed\n","\n","def compute_mic_pair(X: pd.DataFrame, feature_i: str, feature_j: str, B: float):\n","    \"\"\"\n","    Computes the MIC approximation for a pair of features directly from the DataFrame.\n","\n","    Parameters:\n","    X (pd.DataFrame): Input feature matrix\n","    feature_i (str): First feature name\n","    feature_j (str): Second feature name\n","    B (float): Max bin limit (B = n^0.6)\n","\n","    Returns:\n","    tuple: (feature_i, feature_j, MIC value)\n","    \"\"\"\n","    if feature_i == feature_j:\n","        return (feature_i, feature_j, 1.0)  # Self-correlation is always 1\n","\n","    # Limit bins to B = n^0.6 and ensure |X|, |Y| < B\n","    bins_x = min(len(np.unique(X[feature_i])), B)\n","    bins_y = min(len(np.unique(X[feature_j])), B)\n","\n","    # Create 2D histogram\n","    c_xy = np.histogram2d(X[feature_i], X[feature_j], bins=[bins_x, bins_y])[0]\n","\n","    # Compute Mutual Information\n","    mi = mutual_info_score(None, None, contingency=c_xy)\n","\n","    # Normalize MIC using log2(min(|X|, |Y|))\n","    log_min_cardinality = np.log2(min(bins_x, bins_y) + 1)\n","\n","    mic_value = mi / log_min_cardinality if log_min_cardinality > 0 else 0\n","    return (feature_i, feature_j, mic_value)\n","\n","\n","def mic_approx_parallel(X: pd.DataFrame, n_jobs=-1):\n","    \"\"\"\n","    Computes an approximate Maximum Information Coefficient (MIC) matrix for a DataFrame\n","    using mutual information, with parallel processing.\n","\n","    Parameters:\n","    X (pd.DataFrame): Input feature matrix\n","    n_jobs (int): Number of parallel jobs (-1 uses all available CPUs)\n","\n","    Returns:\n","    pd.DataFrame: MIC matrix (bounded [0,1])\n","    \"\"\"\n","    n_samples = X.shape[0]\n","    B = int(np.floor(n_samples ** 0.6))  # Compute max bins limit\n","    feature_names = X.columns.tolist()\n","\n","    feature_pairs = [(feature_names[i], feature_names[j])\n","                     for i in range(len(feature_names))\n","                     for j in range(i, len(feature_names))]\n","    # Compute MIC for each pair in parallel\n","    results = Parallel(n_jobs=n_jobs)(\n","        delayed(compute_mic_pair)(X, feature_i, feature_j, B) for feature_i, feature_j in feature_pairs\n","    )\n","\n","    # Convert results into a symmetric matrix\n","    mic_matrix = pd.DataFrame(np.zeros((len(feature_names), len(feature_names))),\n","                              index=feature_names, columns=feature_names)\n","    for feature_i, feature_j, mic_value in results:\n","        mic_matrix.loc[feature_i, feature_j] = mic_matrix.loc[feature_j, feature_i] = mic_value\n","\n","    return mic_matrix"],"metadata":{"id":"86i88rNPIpmn","executionInfo":{"status":"ok","timestamp":1739649057555,"user_tz":300,"elapsed":108,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def distance_correlation_matrix(df: pd.DataFrame):\n","    \"\"\"Computes the distance correlation coefficient matrix for all pairs of features in the dataframe.\"\"\"\n","    # Initialize an empty DataFrame for the correlation matrix\n","    corr_matrix = pd.DataFrame(np.zeros((df.shape[1], df.shape[1])), columns=df.columns, index=df.columns)\n","\n","    # Loop through each pair of columns in the DataFrame\n","    for col1 in df.columns:\n","        print(col1)\n","        for col2 in df.columns:\n","            # Calculate distance correlation coefficient for the pair (col1, col2)\n","            dCorr = dcor.distance_correlation(df[col1], df[col2])\n","            corr_matrix.loc[col1, col2] = dCorr\n","            corr_matrix.loc[col2, col1] = dCorr  # Since the matrix is symmetrical\n","\n","    return corr_matrix\n","\n","def eliminate_redundant_features(X: pd.DataFrame, mic_matrix: pd.DataFrame, dcor_matrix: pd.DataFrame, shap_importance: pd.DataFrame, threshold=0.8):\n","    \"\"\"\n","    Eliminates redundant features based on MIC, Distance Correlation (Dcor), and SHAP importance.\n","\n","    Parameters:\n","    - X (pd.DataFrame): Feature matrix\n","    - mic_matrix (pd.DataFrame): MIC correlation matrix\n","    - dcor_matrix (pd.DataFrame): Distance Correlation matrix\n","    - shap_importance (pd.DataFrame): DataFrame with SHAP importance (index: feature names, column: 'SHAP_Importance')\n","    - threshold (float): Correlation threshold for considering redundancy\n","\n","    Returns:\n","    - pd.DataFrame: Reduced feature matrix with redundant features removed\n","    - list: List of removed features\n","    \"\"\"\n","\n","    # Step 1: Compute the average redundancy matrix (MIC + Dcor) / 2\n","    combined_matrix = (mic_matrix + dcor_matrix) / 2\n","\n","    # Step 2: Identify highly correlated feature pairs\n","    redundant_pairs = []\n","    for i in range(len(combined_matrix.columns)):\n","        for j in range(i + 1, len(combined_matrix.columns)):\n","            if combined_matrix.iloc[i, j] > threshold:\n","                redundant_pairs.append((combined_matrix.columns[i], combined_matrix.columns[j]))\n","\n","    # Step 3: Eliminate redundant features based on SHAP importance\n","    removed_features = set()\n","    for feature1, feature2 in redundant_pairs:\n","        if feature1 in removed_features or feature2 in removed_features:\n","            continue  # Skip if already removed\n","\n","        # Keep the feature with the higher SHAP importance\n","        if shap_importance.loc[feature1, \"SHAP_Importance\"] >= shap_importance.loc[feature2, \"SHAP_Importance\"]:\n","            removed_features.add(feature2)\n","        else:\n","            removed_features.add(feature1)\n","\n","    # Step 4: Drop redundant features and return the reduced dataset\n","    X_reduced = X.drop(columns=list(removed_features))\n","\n","    return X_reduced, list(removed_features)\n"],"metadata":{"id":"zg8H10qQI0lX","executionInfo":{"status":"ok","timestamp":1739649059040,"user_tz":300,"elapsed":84,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Compute MIC matrix\n","mic_matrix_parallel = mic_approx_parallel(X_train, n_jobs=-1)\n","# Compute distance correlation matrix\n","dCorr_matrix = distance_correlation_matrix(X_train)\n","\n","X_reduced, removed_features = eliminate_redundant_features(X=X_train, mic_matrix=mic_matrix_parallel, dcor_matrix=dCorr_matrix, shap_importance=feature_importance_df, threshold=0.7)\n","\n","print(f\"Removed Features: {removed_features}\")\n","print(f\"Remaining Features: {X_reduced.columns.tolist()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"woh4jdqRI4oT","executionInfo":{"status":"ok","timestamp":1739649285518,"user_tz":300,"elapsed":225527,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"60c774bb-4f7f-4849-a780-11b69d85a96b"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["number_of_elements\n","mean_atomic_mass\n","wtd_mean_atomic_mass\n","gmean_atomic_mass\n","wtd_gmean_atomic_mass\n","entropy_atomic_mass\n","wtd_entropy_atomic_mass\n","range_atomic_mass\n","wtd_range_atomic_mass\n","std_atomic_mass\n","wtd_std_atomic_mass\n","mean_fie\n","wtd_mean_fie\n","gmean_fie\n","wtd_gmean_fie\n","entropy_fie\n","wtd_entropy_fie\n","range_fie\n","wtd_range_fie\n","std_fie\n","wtd_std_fie\n","mean_atomic_radius\n","wtd_mean_atomic_radius\n","gmean_atomic_radius\n","wtd_gmean_atomic_radius\n","entropy_atomic_radius\n","wtd_entropy_atomic_radius\n","range_atomic_radius\n","wtd_range_atomic_radius\n","std_atomic_radius\n","wtd_std_atomic_radius\n","mean_Density\n","wtd_mean_Density\n","gmean_Density\n","wtd_gmean_Density\n","entropy_Density\n","wtd_entropy_Density\n","range_Density\n","wtd_range_Density\n","std_Density\n","wtd_std_Density\n","mean_ElectronAffinity\n","wtd_mean_ElectronAffinity\n","gmean_ElectronAffinity\n","wtd_gmean_ElectronAffinity\n","entropy_ElectronAffinity\n","wtd_entropy_ElectronAffinity\n","range_ElectronAffinity\n","wtd_range_ElectronAffinity\n","std_ElectronAffinity\n","wtd_std_ElectronAffinity\n","mean_FusionHeat\n","wtd_mean_FusionHeat\n","gmean_FusionHeat\n","wtd_gmean_FusionHeat\n","entropy_FusionHeat\n","wtd_entropy_FusionHeat\n","range_FusionHeat\n","wtd_range_FusionHeat\n","std_FusionHeat\n","wtd_std_FusionHeat\n","mean_ThermalConductivity\n","wtd_mean_ThermalConductivity\n","gmean_ThermalConductivity\n","wtd_gmean_ThermalConductivity\n","entropy_ThermalConductivity\n","wtd_entropy_ThermalConductivity\n","range_ThermalConductivity\n","wtd_range_ThermalConductivity\n","std_ThermalConductivity\n","wtd_std_ThermalConductivity\n","mean_Valence\n","wtd_mean_Valence\n","gmean_Valence\n","wtd_gmean_Valence\n","entropy_Valence\n","wtd_entropy_Valence\n","range_Valence\n","wtd_range_Valence\n","std_Valence\n","wtd_std_Valence\n","Removed Features: ['range_Valence', 'number_of_elements', 'mean_Valence']\n","Remaining Features: ['mean_atomic_mass', 'wtd_mean_atomic_mass', 'gmean_atomic_mass', 'wtd_gmean_atomic_mass', 'entropy_atomic_mass', 'wtd_entropy_atomic_mass', 'range_atomic_mass', 'wtd_range_atomic_mass', 'std_atomic_mass', 'wtd_std_atomic_mass', 'mean_fie', 'wtd_mean_fie', 'gmean_fie', 'wtd_gmean_fie', 'entropy_fie', 'wtd_entropy_fie', 'range_fie', 'wtd_range_fie', 'std_fie', 'wtd_std_fie', 'mean_atomic_radius', 'wtd_mean_atomic_radius', 'gmean_atomic_radius', 'wtd_gmean_atomic_radius', 'entropy_atomic_radius', 'wtd_entropy_atomic_radius', 'range_atomic_radius', 'wtd_range_atomic_radius', 'std_atomic_radius', 'wtd_std_atomic_radius', 'mean_Density', 'wtd_mean_Density', 'gmean_Density', 'wtd_gmean_Density', 'entropy_Density', 'wtd_entropy_Density', 'range_Density', 'wtd_range_Density', 'std_Density', 'wtd_std_Density', 'mean_ElectronAffinity', 'wtd_mean_ElectronAffinity', 'gmean_ElectronAffinity', 'wtd_gmean_ElectronAffinity', 'entropy_ElectronAffinity', 'wtd_entropy_ElectronAffinity', 'range_ElectronAffinity', 'wtd_range_ElectronAffinity', 'std_ElectronAffinity', 'wtd_std_ElectronAffinity', 'mean_FusionHeat', 'wtd_mean_FusionHeat', 'gmean_FusionHeat', 'wtd_gmean_FusionHeat', 'entropy_FusionHeat', 'wtd_entropy_FusionHeat', 'range_FusionHeat', 'wtd_range_FusionHeat', 'std_FusionHeat', 'wtd_std_FusionHeat', 'mean_ThermalConductivity', 'wtd_mean_ThermalConductivity', 'gmean_ThermalConductivity', 'wtd_gmean_ThermalConductivity', 'entropy_ThermalConductivity', 'wtd_entropy_ThermalConductivity', 'range_ThermalConductivity', 'wtd_range_ThermalConductivity', 'std_ThermalConductivity', 'wtd_std_ThermalConductivity', 'wtd_mean_Valence', 'gmean_Valence', 'wtd_gmean_Valence', 'entropy_Valence', 'wtd_entropy_Valence', 'wtd_range_Valence', 'std_Valence', 'wtd_std_Valence']\n"]}]},{"cell_type":"code","source":["from deap import base, creator, tools, algorithms  # Genetic Algorithm library\n","import random\n","\n","# ---------------- Step 1: Define Fitness Function ---------------- #\n","def evaluate_feature_subset(individual, X, y):\n","    \"\"\" Evaluates a given feature subset (individual) using CatBoost & cross-validation \"\"\"\n","\n","    # Convert binary feature selection into actual column names\n","    selected_features = [feature for i, feature in enumerate(X.columns) if individual[i] == 1]\n","\n","    # If no features selected, return worst possible score\n","    if len(selected_features) == 0:\n","        return (-float(\"inf\"),)  # Low R² is bad\n","\n","    # Train model only on selected features\n","    model = CatBoostRegressor(iterations=100, depth=6, learning_rate=0.1, verbose=0, random_seed=42)\n","    r2 = np.mean(cross_val_score(model, X[selected_features], y, cv=3, scoring='r2'))  # ✅ Maximize R²\n","\n","    return (r2,)  # GA maximizes R²\n","\n","# ---------------- Step 2: Set Up Genetic Algorithm ---------------- #\n","def run_genetic_algorithm(X, y, population_size=50, generations=20, crossover_prob=0.8, mutation_prob=0.2):\n","    \"\"\"\n","    Runs a Genetic Algorithm to find the optimal subset of features for regression.\n","    \"\"\"\n","\n","    num_features = X.shape[1]\n","\n","    # Define optimization problem: Maximize R²\n","    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # ✅ Maximizing R²\n","    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","    # Define Individual and Population\n","    toolbox = base.Toolbox()\n","    toolbox.register(\"attr_bool\", random.randint, 0, 1)  # Binary selection (0=off, 1=on)\n","    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, num_features)\n","    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","    # Register genetic operations\n","    toolbox.register(\"mate\", tools.cxTwoPoint)  # Crossover\n","    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=mutation_prob)  # Mutation\n","    toolbox.register(\"select\", tools.selTournament, tournsize=3)  # Selection\n","    toolbox.register(\"evaluate\", evaluate_feature_subset, X=X, y=y)\n","\n","    # Initialize population\n","    population = toolbox.population(n=population_size)\n","\n","    # Run GA\n","    result_population, _ = algorithms.eaSimple(population, toolbox, cxpb=crossover_prob, mutpb=mutation_prob,\n","                                               ngen=generations, verbose=True)\n","\n","    # Get best individual (best feature subset)\n","    best_individual = tools.selBest(result_population, k=1)[0]\n","    best_features = [feature for i, feature in enumerate(X.columns) if best_individual[i] == 1]\n","\n","    return best_features"],"metadata":{"id":"NjbwmEYbJPzH","executionInfo":{"status":"ok","timestamp":1739649334545,"user_tz":300,"elapsed":117,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["reduced_features = [i for i in feature_importance_df[feature_importance_df['SHAP_Importance'] != 0].index.tolist() if i not in removed_features]\n","X_original = X_reduced[reduced_features]\n","\n","best_features = run_genetic_algorithm(X_original, y_train, population_size=20, generations=5)\n","\n","print(f\"Best Features Selected by GA: {best_features}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87Vc7AiPJXoR","executionInfo":{"status":"ok","timestamp":1739649687551,"user_tz":300,"elapsed":348961,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"d444d0d2-1647-45f8-a1c0-37dd7b4993c6"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["gen\tnevals\n","0  \t20    \n","1  \t16    \n","2  \t18    \n","3  \t14    \n","4  \t14    \n","5  \t18    \n","Best Features Selected by GA: ['range_ThermalConductivity', 'wtd_gmean_ThermalConductivity', 'range_atomic_radius', 'wtd_gmean_Valence', 'wtd_std_ThermalConductivity', 'wtd_std_ElectronAffinity', 'mean_Density', 'wtd_entropy_ThermalConductivity', 'gmean_Density', 'wtd_std_Valence', 'std_Density', 'wtd_range_fie', 'std_atomic_radius', 'wtd_range_atomic_mass', 'wtd_range_ElectronAffinity', 'wtd_entropy_atomic_mass', 'wtd_entropy_Density', 'wtd_std_atomic_mass', 'wtd_std_Density', 'wtd_entropy_FusionHeat', 'entropy_atomic_mass', 'wtd_entropy_ElectronAffinity', 'entropy_ThermalConductivity', 'wtd_mean_ElectronAffinity', 'entropy_atomic_radius', 'wtd_gmean_Density', 'wtd_mean_Density', 'wtd_range_FusionHeat', 'wtd_std_FusionHeat', 'wtd_mean_fie', 'wtd_gmean_fie', 'wtd_range_Density', 'wtd_gmean_FusionHeat', 'wtd_range_ThermalConductivity', 'gmean_fie', 'mean_fie', 'mean_atomic_radius', 'gmean_atomic_radius', 'mean_ElectronAffinity', 'mean_FusionHeat', 'mean_atomic_mass', 'gmean_Valence', 'entropy_ElectronAffinity', 'range_ElectronAffinity']\n"]}]},{"cell_type":"code","source":["X = X_reduced[best_features].values\n","y = y_train.values\n","\n","X_dup = np.concatenate([X] * 5, axis=0)\n","y_dup = np.concatenate([y] * 5, axis=0)\n","\n","# Shuffle both X_dup and y_dup together while keeping alignment\n","X, y = shuffle(X_dup, y_dup, random_state=42)"],"metadata":{"id":"ZzYEB8qcMA7-","executionInfo":{"status":"ok","timestamp":1739652356083,"user_tz":300,"elapsed":103,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["# Define KFold\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","\n","\n","# Store results\n","mse_scores = []\n","y_preds = []\n","\n","# Perform K-Fold training\n","for fold, (train_index, test_index) in enumerate(kf.split(X), start=1):\n","    X_train2, X_test2 = X[train_index], X[test_index]\n","    y_train2, y_test2 = y[train_index], y[test_index]\n","\n","    # **New Step: Split training into actual train and validation**\n","    X_train_final, X_val, y_train_final, y_val = train_test_split(\n","        X_train2, y_train2, test_size=0.2, random_state=42\n","    )\n","    # Initialize model\n","    model = XGBRegressor(n_estimators=100, subsample=0.6, reg_lambda=3,\n","                      reg_alpha=0.1, min_child_weight=5, max_depth=10,\n","                      learning_rate=0.05, gamma=0.5, colsample_bytree=0.8,\n","                      random_state=42)\n","    # Train the model with early stopping\n","    model.fit(\n","        X_train_final, y_train_final,\n","        eval_set=[(X_val, y_val)],\n","        verbose=False\n","    )\n","\n","    # Predict on the test set (never seen before)\n","    y_pred = model.predict(X_test2)\n","    y_preds.append(y_pred)\n","\n","    # Compute MSE for this fold\n","    mse = mean_squared_error(y_test2, y_pred)\n","    mse_scores.append(mse)\n","\n","    print(f\"Fold {fold}: MSE = {mse:.4f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBSVnKLDJcIg","executionInfo":{"status":"ok","timestamp":1739652411482,"user_tz":300,"elapsed":41419,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"3330d823-6905-4843-c847-33de63f25b74"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1: MSE = 37.5209\n","Fold 2: MSE = 40.2129\n","Fold 3: MSE = 43.1075\n","Fold 4: MSE = 38.4854\n","Fold 5: MSE = 40.5744\n"]}]},{"cell_type":"code","source":["\n","y_pred = model.predict(X_test[best_features].values)\n","name = 'XGB Final'\n","print(f\"{name} MSE: {mean_squared_error(y_test.values, y_pred)}\")\n","print(f\"{name} R²: {r2_score(y_test.values, y_pred)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_IHuZTwNBZN","executionInfo":{"status":"ok","timestamp":1739652424243,"user_tz":300,"elapsed":110,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"f3b446fc-36c3-43e7-a046-cfc9e5d674ee"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["XGB Final MSE: 83.71458147143977\n","XGB Final R²: 0.9264266786604417\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","# Convert data to DMatrix (XGBoost's optimized data structure)\n","dtrain = xgb.DMatrix(X, label=y)\n","\n","# Define XGBoost parameters\n","params = {\n","    \"objective\": \"reg:squarederror\",\n","    \"n_estimators\": 100,\n","    \"subsample\": 0.6,\n","    \"reg_lambda\": 1,\n","    \"reg_alpha\": 0.1,\n","    \"min_child_weight\": 5,\n","    \"max_depth\": 10,\n","    \"learning_rate\": 0.05,\n","    \"gamma\": 0.5,\n","    \"colsample_bytree\": 0.8,\n","    \"random_state\": 42,\n","}\n","\n","# Perform cross-validation\n","cv_results = xgb.cv(\n","    params,\n","    dtrain,\n","    num_boost_round=300,  # Equivalent to n_estimators\n","    nfold=5,  # 5-fold cross-validation\n","    metrics=\"rmse\",\n","    early_stopping_rounds=10,  # Stops training if validation error doesn't improve\n","    as_pandas=True,  # Get results as a DataFrame\n","    seed=42,\n",")\n","\n","# Print final results\n","print(cv_results.tail(5))  # Shows last few rounds of training\n","\n","# Extract best RMSE score\n","best_rmse = cv_results[\"test-rmse-mean\"].min()\n","print(f\"Best Test RMSE: {best_rmse:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5YrXA2UOjpY","executionInfo":{"status":"ok","timestamp":1739652517296,"user_tz":300,"elapsed":64542,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"9630771e-66e7-478d-d95c-2a28bf9af4ee"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:47:32] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"n_estimators\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:47:33] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"n_estimators\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:47:34] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"n_estimators\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["     train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n","295         4.366397        0.030927        4.784158       0.131464\n","296         4.364650        0.031152        4.781549       0.131417\n","297         4.363446        0.031115        4.780251       0.132616\n","298         4.362175        0.031363        4.779473       0.132225\n","299         4.360342        0.031068        4.777819       0.133022\n","Best Test RMSE: 4.7778\n"]}]},{"cell_type":"code","source":["best_rounds = cv_results.shape[0]\n","print(f\"Best number of boosting rounds: {best_rounds}\")\n","\n","# Train final model using best_rounds\n","final_model = xgb.train(params, dtrain, num_boost_round=best_rounds)\n","\n","# Test on new data\n","dtest = xgb.DMatrix(X_test[best_features].values)\n","y_pred = final_model.predict(dtest)\n","\n","# Compute test MSE\n","test_mse = mean_squared_error(y_test.values, y_pred)\n","print(f\"Test MSE: {test_mse:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBEjJG7SU0gR","executionInfo":{"status":"ok","timestamp":1739652597214,"user_tz":300,"elapsed":13302,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"89ea5b29-1cb2-4eed-b130-36e8f7c3e128"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Best number of boosting rounds: 300\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:49:43] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"n_estimators\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Test MSE: 83.5239\n"]}]},{"cell_type":"markdown","source":["**Part 3: Predictions**"],"metadata":{"id":"-N-qKFNAcTXF"}},{"cell_type":"code","source":["material_elements = formula_test.drop(columns=[\"material\"])\n","material_elements = material_elements.astype(float)\n","# Initialize a list to store merged data\n","merged_data = []\n","\n","# Iterate through each material in material_elements with a progress bar\n","for material_index, material_row in tqdm(material_elements.iterrows(), total=len(material_elements), desc=\"Processing materials\"):\n","    material_name = material_row.name  # Material is the index (name) of the row\n","\n","    # Get the non-zero element counts for this material\n","    elements_in_material = material_row[material_row > 0].index.tolist()  # List of elements in material with non-zero counts\n","\n","    # Create a temporary DataFrame for the current material\n","    material_data = []\n","\n","    for i in range(10):  # Maximum 10 rows per material\n","        if i < len(elements_in_material):\n","            element = elements_in_material[i]\n","            element_info = element_features[element_features['Element'] == element].copy()\n","            # Add element count (how many times this element occurs) to the feature data\n","            element_info['count'] = material_row[element]\n","        else:\n","            # Fill with zeros for padding\n","            element_info = pd.DataFrame(np.zeros((1, len(element_features.columns) + 1)),\n","                                        columns=element_features.columns.tolist() + ['count'])\n","\n","        # Append the element's features to the material data\n","        material_data.append(element_info)\n","\n","    # Combine material data into a single DataFrame for this material\n","    material_df = pd.concat(material_data, ignore_index=True)\n","    material_df['material_name'] = material_name  # Add the material name as a column\n","\n","    # Append the material's data to the merged dataset\n","    merged_data.append(material_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtUNIq4EcXJ7","executionInfo":{"status":"ok","timestamp":1739654402157,"user_tz":300,"elapsed":33800,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"12a5ac64-eb89-46ba-a7dc-e80aa53f4ed8"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing materials: 100%|██████████| 4253/4253 [00:33<00:00, 126.47it/s]\n"]}]},{"cell_type":"code","source":["# Combine all material data into a single DataFrame\n","features = ['count','AtomicMass','AtomicNumber','FirstIonizationEnergy','AtomicRadius','BoilingPoint',\n","            'Density','ElectronAffinity','Electronegativity','FusionHeat','MeltingPoint','SpecificHeat',\n","            'ThermalConductivity','ThermalExpansion','Valence','MolarVolume','Period', 'material_name'\n","]\n","final_df = pd.concat(merged_data, ignore_index=True)\n","formula_df = final_df[features]\n","\n","# Group by material_name to get arrays for CNN\n","grouped_fixed = []\n","for material_name, group in formula_df.groupby('material_name'):\n","    arr = group.drop(['material_name'], axis=1).values\n","    grouped_fixed.append(arr)\n","\n","X = np.array(grouped_fixed).reshape(-1, 10, 17)\n","X = np.nan_to_num(X, nan=0.0)\n","\n","print(f\"X.shape: {X.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqFSrRuReZMl","executionInfo":{"status":"ok","timestamp":1739656020072,"user_tz":300,"elapsed":5108,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"f24df0a1-3725-4c54-d74f-33327880bb9b"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["X.shape: (4253, 10, 17)\n"]}]},{"cell_type":"code","source":["X_flat = X.reshape(-1, X.shape[-1])  # Now X_flat has shape (17000 * 10, 17)\n","\n","# Initialize the StandardScaler\n","scaler = StandardScaler()\n","\n","# Fit and transform the features\n","X_scaled_flat = scaler.fit_transform(X_flat)\n","\n","# Reshape back to the original 3D shape: (17000, 10, 17)\n","X = X_scaled_flat.reshape(X.shape)"],"metadata":{"id":"PZ7FdhSWecfk","executionInfo":{"status":"ok","timestamp":1739656021831,"user_tz":300,"elapsed":108,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["y_pred_c1_test = model_c1.predict(X).reshape(-1)\n","y_pred_c2_test = model_c2.predict(X).reshape(-1)\n","y_pred_r1_test = model_r1.predict(X).reshape(-1)\n","\n","X_meta_test = np.column_stack([y_pred_c1_test, y_pred_c2_test, y_pred_r1_test])\n","\n","# Make final predictions using the meta-learner\n","y_pred_ensemble = ridge.predict(X_meta_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNPTncnQfGMj","executionInfo":{"status":"ok","timestamp":1739654583496,"user_tz":300,"elapsed":22247,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}},"outputId":"4430a26f-b51a-4d14-abad-9707f529c1a0"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step\n","\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"]}]},{"cell_type":"code","source":["output = pd.DataFrame(y_pred_ensemble)\n","output.columns = ['critical_temp']\n","output.to_csv('gdrive/MyDrive/Learning/Superconductivity/predictions.csv', index_label = 'index')"],"metadata":{"id":"xZkpXq2Wfn9f","executionInfo":{"status":"ok","timestamp":1739654963485,"user_tz":300,"elapsed":102,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["output = pd.DataFrame(y_pred_r1_test)\n","output.columns = ['critical_temp']\n","output.to_csv('gdrive/MyDrive/Learning/Superconductivity/predictions_r1.csv', index_label = 'index')"],"metadata":{"id":"HN29FAgCicTA","executionInfo":{"status":"ok","timestamp":1739655378373,"user_tz":300,"elapsed":104,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["output = pd.DataFrame(y_pred_c1_test)\n","output.columns = ['critical_temp']\n","output.to_csv('gdrive/MyDrive/Learning/Superconductivity/predictions_c1.csv', index_label = 'index')"],"metadata":{"id":"-3lykE1ojBmL","executionInfo":{"status":"ok","timestamp":1739655508756,"user_tz":300,"elapsed":134,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["scaler = StandardScaler()\n","X = pd.DataFrame(scaler.fit_transform(test), columns=test.columns)\n","\n","y_pred_xgb = model.predict(X[best_features].values)\n"],"metadata":{"id":"7-pZ7P3QgK3Z","executionInfo":{"status":"ok","timestamp":1739655686900,"user_tz":300,"elapsed":227,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["output = pd.DataFrame(y_pred_xgb)\n","output.columns = ['critical_temp']\n","output.to_csv('gdrive/MyDrive/Learning/Superconductivity/predictions_xgb.csv', index_label = 'index')"],"metadata":{"id":"-Sf_18vmiW8e","executionInfo":{"status":"ok","timestamp":1739655717538,"user_tz":300,"elapsed":108,"user":{"displayName":"Charanjit Mosare","userId":"12131224220900402396"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sHJSQwfSs9VI"},"execution_count":null,"outputs":[]}]}